{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import rbf_kernel, sigmoid_kernel, polynomial_kernel\n",
    "from tempfile import TemporaryFile\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "from sklearn.preprocessing import KernelCenterer\n",
    "from typing import Any, Dict, Union, Tuple, List\n",
    "from pprint import pprint\n",
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "import sys\n",
    "maindir = '/'.join(os.getcwd().split('/')[:-1])\n",
    "sys.path.append(maindir)\n",
    "from source.utils import make_symmetric_matrix_psd, normalize, make_kernel_combinations\n",
    "from source.utils import multitask, make_kernel_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate kernel matrices per parameter and kernel combination  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kerneldir = os.path.join(maindir, 'data/precomputed_multitask_kernels')\n",
    "input_file = os.path.join(maindir, \"data/kernel_parameter.csv\")\n",
    "kernel_param = np.array(pd.read_csv(input_file))\n",
    "kernel_param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make kernel parameter combinations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_comb_sig_rbf_rbf = make_kernel_combinations(kernel_param, \"sigmoid_kernel\", \"rbf_kernel\", \"rbf_kernel\")\n",
    "kernel_comb_sig_rbf_rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_comb_rbf_rbf_rbf = make_kernel_combinations(kernel_param, \"rbf_kernel\", \"rbf_kernel\", \"rbf_kernel\")\n",
    "kernel_comb_rbf_rbf_rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_comb_sig_poly_poly = make_kernel_combinations(kernel_param, \"sigmoid_kernel\", \"poly_kernel\", \"poly_kernel\")\n",
    "kernel_comb_sig_poly_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_comb_rbf_poly_poly = make_kernel_combinations(kernel_param, \"rbf_kernel\", \"poly_kernel\", \"poly_kernel\")\n",
    "kernel_comb_rbf_poly_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_comb_sig_rbf_poly = make_kernel_combinations(kernel_param, \"sigmoid_kernel\", \"rbf_kernel\", \"poly_kernel\")\n",
    "kernel_comb_sig_rbf_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_comb_rbf_rbf_poly = make_kernel_combinations(kernel_param, \"rbf_kernel\", \"rbf_kernel\", \"poly_kernel\")\n",
    "kernel_comb_rbf_rbf_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_comb_sig_poly_rbf = make_kernel_combinations(kernel_param, \"sigmoid_kernel\", \"poly_kernel\", \"rbf_kernel\")\n",
    "kernel_comb_sig_poly_rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_comb_rbf_poly_rbf = make_kernel_combinations(kernel_param, \"rbf_kernel\", \"poly_kernel\", \"rbf_kernel\")\n",
    "kernel_comb_rbf_poly_rbf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save kernel parameter combinations as grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = os.path.join(maindir, 'data/precomputed_multitask_kernels/kernel_comb_SRR.json')\n",
    "with open(fn, 'w') as fp:\n",
    "    json.dump({k: v.tolist() for k, v in kernel_comb_sig_rbf_rbf.items()}, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = os.path.join(maindir, 'data/precomputed_multitask_kernels/kernel_comb_RRR.json')\n",
    "with open(fn, 'w') as fp:\n",
    "    json.dump({k: v.tolist() for k, v in kernel_comb_rbf_rbf_rbf.items()}, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = os.path.join(maindir, 'data/precomputed_multitask_kernels/kernel_comb_SPP.json')\n",
    "with open(fn, 'w') as fp:\n",
    "    json.dump({k: v.tolist() for k, v in kernel_comb_sig_poly_poly.items()}, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = os.path.join(maindir, 'data/precomputed_multitask_kernels/kernel_comb_RPP.json')\n",
    "with open(fn, 'w') as fp:\n",
    "    json.dump({k: v.tolist() for k, v in kernel_comb_rbf_poly_poly.items()}, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = os.path.join(maindir, 'data/precomputed_multitask_kernels/kernel_comb_SRP.json')\n",
    "with open(fn, 'w') as fp:\n",
    "    json.dump({k: v.tolist() for k, v in kernel_comb_sig_rbf_poly.items()}, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = os.path.join(maindir, 'data/precomputed_multitask_kernels/kernel_comb_RRP.json')\n",
    "with open(fn, 'w') as fp:\n",
    "    json.dump({k: v.tolist() for k, v in kernel_comb_rbf_rbf_poly.items()}, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = os.path.join(maindir, 'data/precomputed_multitask_kernels/kernel_comb_SPR.json')\n",
    "with open(fn, 'w') as fp:\n",
    "    json.dump({k: v.tolist() for k, v in kernel_comb_sig_poly_rbf.items()}, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = os.path.join(maindir, 'data/precomputed_multitask_kernels/kernel_comb_RPR.json')\n",
    "with open(fn, 'w') as fp:\n",
    "    json.dump({k: v.tolist() for k, v in kernel_comb_rbf_poly_rbf.items()}, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make kernel matrices with different kernel combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whole proteome data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = os.path.join(maindir, \"data/proteome_data/preprocessed_whole_data.csv\")\n",
    "data_malaria = pd.read_csv(input_data)\n",
    "data_malaria.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selective proteome data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load file via pandas as csv file \n",
    "input_file_s = os.path.join(maindir, \"data/proteome_data/preprocessed_selective_data.csv\")\n",
    "selected_data_malaria = pd.read_csv(input_file_s)\n",
    "selected_data_malaria.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(\n",
    "    identifier: str,\n",
    "    data: pd.DataFrame,\n",
    "    kernel_param: dict,\n",
    "    kernel_for_time_series: str,\n",
    "    kernel_for_dosage: str,\n",
    "    kernel_for_abSignal: str,\n",
    "    save_to_dir: str,\n",
    "    scale: bool = False,\n",
    ") -> Dict[str, List[Any]]:\n",
    "\n",
    "    collection = dict()\n",
    "    collection['models'] = []\n",
    "    collection['kernel_matrices'] = []\n",
    "    collection['information'] = []\n",
    "    collection['damping_values_list'] = []\n",
    "    if kernel_for_time_series == \"sigmoid_kernel\" and kernel_for_dosage == \"rbf_kernel\" and kernel_for_abSignal == \"rbf_kernel\":\n",
    "        for m in product(kernel_param[\"SA\"], kernel_param[\"SO\"], kernel_param[\"R0\"], kernel_param[\"R1\"], kernel_param[\"R2\"], kernel_param[\"P1\"], kernel_param[\"P2\"]):\n",
    "            kernel_matrix, damping_values, info = make_kernel_matrix(\n",
    "                AB_signals=data.drop(columns=['Patient', 'group', 'Protection', 'TimePointOrder', 'Dose']),\n",
    "                time_series=data['TimePointOrder'],\n",
    "                dose=data['Dose'],\n",
    "                model=m,\n",
    "                kernel_time_series=kernel_for_time_series,\n",
    "                kernel_dosage=kernel_for_dosage,\n",
    "                kernel_abSignals=kernel_for_abSignal,\n",
    "                scale=scale,\n",
    "            )\n",
    "            collection['models'].append(m)\n",
    "            collection['kernel_matrices'].append(kernel_matrix)\n",
    "            collection['information'].append(info)\n",
    "            collection['damping_values_list'].append(damping_values)\n",
    "            output_file_name = f\"{identifier}_SRR_SA_{m[0]}_SO_{m[1]}_R0_{m[2]}_R1_{m[3]:.1E}_R2_{m[4]:.1E}_P1_{m[5]}_P2_{m[6]}.npy\"\n",
    "            np.save(os.path.join(save_to_dir, output_file_name), kernel_matrix)\n",
    "\n",
    "    elif kernel_for_time_series == \"sigmoid_kernel\" and kernel_for_dosage == \"poly_kernel\" and kernel_for_abSignal == \"rbf_kernel\":\n",
    "        for m in product(kernel_param[\"SA\"], kernel_param[\"SO\"], kernel_param[\"R0\"], kernel_param[\"R1\"], kernel_param[\"R2\"], kernel_param[\"P1\"], kernel_param[\"P2\"]):\n",
    "            kernel_matrix, damping_values, info = make_kernel_matrix(\n",
    "                AB_signals=data.drop(columns=['Patient', 'group', 'Protection', 'TimePointOrder', 'Dose']),\n",
    "                time_series=data['TimePointOrder'],\n",
    "                dose=data['Dose'],\n",
    "                model=m,\n",
    "                kernel_time_series=kernel_for_time_series,\n",
    "                kernel_dosage=kernel_for_dosage,\n",
    "                kernel_abSignals=kernel_for_abSignal,\n",
    "                scale=scale,\n",
    "            )\n",
    "            collection['models'].append(m)\n",
    "            collection['kernel_matrices'].append(kernel_matrix)\n",
    "            collection['information'].append(info)\n",
    "            collection['damping_values_list'].append(damping_values)\n",
    "            output_file_name = f\"{identifier}_SPR_SA_{m[0]}_SO_{m[1]}_R0_{m[2]}_R1_{m[3]}_R2_{m[4]:.1E}_P1_{m[5]}_P2_{m[6]}.npy\"\n",
    "            np.save(os.path.join(save_to_dir, output_file_name), kernel_matrix)\n",
    "            \n",
    "    elif kernel_for_time_series == \"sigmoid_kernel\" and kernel_for_dosage == \"rbf_kernel\" and kernel_for_abSignal == \"poly_kernel\":\n",
    "        for m in product(kernel_param[\"SA\"], kernel_param[\"SO\"], kernel_param[\"R0\"], kernel_param[\"R1\"], kernel_param[\"R2\"], kernel_param[\"P1\"], kernel_param[\"P2\"]):\n",
    "            kernel_matrix, damping_values, info = make_kernel_matrix(\n",
    "                AB_signals=data.drop(columns=['Patient', 'group', 'Protection', 'TimePointOrder', 'Dose']),\n",
    "                time_series=data['TimePointOrder'],\n",
    "                dose=data['Dose'],\n",
    "                model=m,\n",
    "                kernel_time_series=kernel_for_time_series,\n",
    "                kernel_dosage=kernel_for_dosage,\n",
    "                kernel_abSignals=kernel_for_abSignal,\n",
    "                scale=scale,\n",
    "            )\n",
    "            collection['models'].append(m)\n",
    "            collection['kernel_matrices'].append(kernel_matrix)\n",
    "            collection['information'].append(info)\n",
    "            collection['damping_values_list'].append(damping_values)\n",
    "            output_file_name = f\"{identifier}_SRP_SA_{m[0]}_SO_{m[1]}_R0_{m[2]}_R1_{m[3]:.1E}_R2_{m[4]}_P1_{m[5]}_P2_{m[6]}.npy\"\n",
    "            np.save(os.path.join(save_to_dir, output_file_name), kernel_matrix)\n",
    "            \n",
    "    elif kernel_for_time_series == \"sigmoid_kernel\" and kernel_for_dosage == \"poly_kernel\" and kernel_for_abSignal == \"poly_kernel\":\n",
    "        for m in product(kernel_param[\"SA\"], kernel_param[\"SO\"], kernel_param[\"R0\"], kernel_param[\"R1\"], kernel_param[\"R2\"], kernel_param[\"P1\"], kernel_param[\"P2\"]):\n",
    "            kernel_matrix, damping_values, info = make_kernel_matrix(\n",
    "                AB_signals=data.drop(columns=['Patient', 'group', 'Protection', 'TimePointOrder', 'Dose']),\n",
    "                time_series=data['TimePointOrder'],\n",
    "                dose=data['Dose'],\n",
    "                model=m,\n",
    "                kernel_time_series=kernel_for_time_series,\n",
    "                kernel_dosage=kernel_for_dosage,\n",
    "                kernel_abSignals=kernel_for_abSignal,\n",
    "                scale=scale,\n",
    "            )\n",
    "            collection['models'].append(m)\n",
    "            collection['kernel_matrices'].append(kernel_matrix)\n",
    "            collection['information'].append(info)\n",
    "            collection['damping_values_list'].append(damping_values)\n",
    "            output_file_name = f\"{identifier}_SPP_SA_{m[0]}_SO_{m[1]}_R0_{m[2]}_R1_{m[3]}_R2_{m[4]}_P1_{m[5]}_P2_{m[6]}.npy\"\n",
    "            np.save(os.path.join(save_to_dir, output_file_name), kernel_matrix)\n",
    "    elif kernel_for_time_series == \"rbf_kernel\" and kernel_for_dosage == \"rbf_kernel\" and kernel_for_abSignal == \"rbf_kernel\":\n",
    "        for m in product(kernel_param[\"SA\"], kernel_param[\"SO\"], kernel_param[\"R0\"], kernel_param[\"R1\"], kernel_param[\"R2\"], kernel_param[\"P1\"], kernel_param[\"P2\"]):\n",
    "            kernel_matrix, damping_values, info = make_kernel_matrix(\n",
    "                AB_signals=data.drop(columns=['Patient', 'group', 'Protection', 'TimePointOrder', 'Dose']),\n",
    "                time_series=data['TimePointOrder'],\n",
    "                dose=data['Dose'],\n",
    "                model=m,\n",
    "                kernel_time_series=kernel_for_time_series,\n",
    "                kernel_dosage=kernel_for_dosage,\n",
    "                kernel_abSignals=kernel_for_abSignal,\n",
    "                scale=scale,\n",
    "            )\n",
    "            collection['models'].append(m)\n",
    "            collection['kernel_matrices'].append(kernel_matrix)\n",
    "            collection['information'].append(info)\n",
    "            collection['damping_values_list'].append(damping_values)\n",
    "            output_file_name = f\"{identifier}_RRR_SA_{m[0]}_SO_{m[1]}_R0_{m[2]:.1E}_R1_{m[3]:.1E}_R2_{m[4]:.1E}_P1_{m[5]}_P2_{m[6]}.npy\"\n",
    "            np.save(os.path.join(save_to_dir, output_file_name), kernel_matrix)\n",
    "\n",
    "    elif kernel_for_time_series == \"rbf_kernel\" and kernel_for_dosage == \"poly_kernel\" and kernel_for_abSignal == \"rbf_kernel\":\n",
    "        for m in product(kernel_param[\"SA\"], kernel_param[\"SO\"], kernel_param[\"R0\"], kernel_param[\"R1\"], kernel_param[\"R2\"], kernel_param[\"P1\"], kernel_param[\"P2\"]):\n",
    "            kernel_matrix, damping_values, info = make_kernel_matrix(\n",
    "                AB_signals=data.drop(columns=['Patient', 'group', 'Protection', 'TimePointOrder', 'Dose']),\n",
    "                time_series=data['TimePointOrder'],\n",
    "                dose=data['Dose'],\n",
    "                model=m,\n",
    "                kernel_time_series=kernel_for_time_series,\n",
    "                kernel_dosage=kernel_for_dosage,\n",
    "                kernel_abSignals=kernel_for_abSignal,\n",
    "                scale=scale,\n",
    "            )\n",
    "            collection['models'].append(m)\n",
    "            collection['kernel_matrices'].append(kernel_matrix)\n",
    "            collection['information'].append(info)\n",
    "            collection['damping_values_list'].append(damping_values)\n",
    "            output_file_name = f\"{identifier}_RPR_SA_{m[0]}_SO_{m[1]}_R0_{m[2]:.1E}_R1_{m[3]}_R2_{m[4]:.1E}_P1_{m[5]}_P2_{m[6]}.npy\"\n",
    "            np.save(os.path.join(save_to_dir, output_file_name), kernel_matrix)\n",
    "            \n",
    "    elif kernel_for_time_series == \"rbf_kernel\" and kernel_for_dosage == \"rbf_kernel\" and kernel_for_abSignal == \"poly_kernel\":\n",
    "        for m in product(kernel_param[\"SA\"], kernel_param[\"SO\"], kernel_param[\"R0\"], kernel_param[\"R1\"], kernel_param[\"R2\"], kernel_param[\"P1\"], kernel_param[\"P2\"]):\n",
    "            kernel_matrix, damping_values, info = make_kernel_matrix(\n",
    "                AB_signals=data.drop(columns=['Patient', 'group', 'Protection', 'TimePointOrder', 'Dose']),\n",
    "                time_series=data['TimePointOrder'],\n",
    "                dose=data['Dose'],\n",
    "                model=m,\n",
    "                kernel_time_series=kernel_for_time_series,\n",
    "                kernel_dosage=kernel_for_dosage,\n",
    "                kernel_abSignals=kernel_for_abSignal,\n",
    "                scale=scale,\n",
    "            )\n",
    "            collection['models'].append(m)\n",
    "            collection['kernel_matrices'].append(kernel_matrix)\n",
    "            collection['information'].append(info)\n",
    "            collection['damping_values_list'].append(damping_values)\n",
    "            output_file_name = f\"{identifier}_RRP_SA_{m[0]}_SO_{m[1]}_R0_{m[2]:.1E}_R1_{m[3]:.1E}_R2_{m[4]}_P1_{m[5]}_P2_{m[6]}.npy\"\n",
    "            np.save(os.path.join(save_to_dir, output_file_name), kernel_matrix)\n",
    "            \n",
    "    elif kernel_for_time_series == \"rbf_kernel\" and kernel_for_dosage == \"poly_kernel\" and kernel_for_abSignal == \"poly_kernel\":\n",
    "        for m in product(kernel_param[\"SA\"], kernel_param[\"SO\"], kernel_param[\"R0\"], kernel_param[\"R1\"], kernel_param[\"R2\"], kernel_param[\"P1\"], kernel_param[\"P2\"]):\n",
    "            kernel_matrix, damping_values, info = make_kernel_matrix(\n",
    "                AB_signals=data.drop(columns=['Patient', 'group', 'Protection', 'TimePointOrder', 'Dose']),\n",
    "                time_series=data['TimePointOrder'],\n",
    "                dose=data['Dose'],\n",
    "                model=m,\n",
    "                kernel_time_series=kernel_for_time_series,\n",
    "                kernel_dosage=kernel_for_dosage,\n",
    "                kernel_abSignals=kernel_for_abSignal,\n",
    "                scale=scale,\n",
    "            )\n",
    "            collection['models'].append(m)\n",
    "            collection['kernel_matrices'].append(kernel_matrix)\n",
    "            collection['information'].append(info)\n",
    "            collection['damping_values_list'].append(damping_values)\n",
    "            output_file_name = f\"{identifier}_RPP_SA_{m[0]}_SO_{m[1]}_R0_{m[2]:.1E}_R1_{m[3]}_R2_{m[4]}_P1_{m[5]}_P2_{m[6]}.npy\"\n",
    "            np.save(os.path.join(save_to_dir, output_file_name), kernel_matrix)\n",
    "\n",
    "    return collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap2d(arr: np.ndarray):\n",
    "    plt.figure(figsize=(9.5, 8))\n",
    "    plt.imshow(arr, cmap='hot')\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overview(collection):\n",
    "    damping_value_sums = []\n",
    "    for i in collection['damping_values_list']:\n",
    "        damping_value_sums.append(np.sum(i))\n",
    "    print('maximum sum:', np.max(damping_value_sums))\n",
    "    print('sorted sums:', np.sort(damping_value_sums)[::-1])\n",
    "    print('')\n",
    "\n",
    "    for i in range(10):\n",
    "        print(collection['models'][i])\n",
    "        print(np.sum(collection['damping_values_list'][i]))\n",
    "        plt.plot(np.sort(np.linalg.eigvals(collection['kernel_matrices'][i]), kind='mergesort')[::-1], marker='.')\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        heatmap2d(collection['kernel_matrices'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SRR unscaled\n",
    "\n",
    "collection_SRR = main(\n",
    "    identifier='kernel_matrix',\n",
    "    data=data_malaria,\n",
    "    kernel_param=kernel_comb_sig_rbf_rbf,\n",
    "    kernel_for_time_series=\"sigmoid_kernel\",\n",
    "    kernel_for_dosage=\"rbf_kernel\",\n",
    "    kernel_for_abSignal=\"rbf_kernel\",\n",
    "    save_to_dir=os.path.join(kerneldir, 'unscaled'),\n",
    ")\n",
    "fn = os.path.join(kerneldir, 'unfiltered/collected_damping_info_SRR.json')\n",
    "with open(fn, 'w') as fp:\n",
    "    json.dump({x: collection_SRR[x] for x in collection_SRR if x not in 'kernel_matrices'}, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overview(collection_SRR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RRR unscaled\n",
    "\n",
    "collection_RRR = main(\n",
    "    identifier='kernel_matrix',\n",
    "    data=data_malaria,\n",
    "    kernel_param=kernel_comb_rbf_rbf_rbf,\n",
    "    kernel_for_time_series=\"rbf_kernel\",\n",
    "    kernel_for_dosage=\"rbf_kernel\",\n",
    "    kernel_for_abSignal=\"rbf_kernel\",\n",
    "    save_to_dir=os.path.join(kerneldir, 'unscaled'),\n",
    ")\n",
    "fn = os.path.join(kerneldir, 'unfiltered/collected_damping_info_RRR.json')\n",
    "with open(fn, 'w') as fp:\n",
    "    json.dump({x: collection_RRR[x] for x in collection_RRR if x not in 'kernel_matrices'}, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overview(collection_RRR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SRP unscaled\n",
    "\n",
    "collection_SRP = main(\n",
    "    identifier='kernel_matrix',\n",
    "    data=data_malaria,\n",
    "    kernel_param=kernel_comb_sig_rbf_poly,\n",
    "    kernel_for_time_series=\"sigmoid_kernel\",\n",
    "    kernel_for_dosage=\"rbf_kernel\",\n",
    "    kernel_for_abSignal=\"poly_kernel\",\n",
    "    save_to_dir=os.path.join(kerneldir, 'unscaled'),\n",
    ")\n",
    "fn = os.path.join(kerneldir, 'unfiltered/collected_damping_info_SRP.json')\n",
    "with open(fn, 'w') as fp:\n",
    "    json.dump({x: collection_SRP[x] for x in collection_SRP if x not in 'kernel_matrices'}, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overview(collection_SRP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RRP unscaled\n",
    "\n",
    "collection_RRP = main(\n",
    "    identifier='kernel_matrix',\n",
    "    data=data_malaria,\n",
    "    kernel_param=kernel_comb_rbf_rbf_poly,\n",
    "    kernel_for_time_series=\"rbf_kernel\",\n",
    "    kernel_for_dosage=\"rbf_kernel\",\n",
    "    kernel_for_abSignal=\"poly_kernel\",\n",
    "    save_to_dir=os.path.join(kerneldir, 'unscaled'),\n",
    ")\n",
    "fn = os.path.join(kerneldir, 'unfiltered/collected_damping_info_RRP.json')\n",
    "with open(fn, 'w') as fp:\n",
    "    json.dump({x: collection_RRP[x] for x in collection_RRP if x not in 'kernel_matrices'}, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overview(collection_RRP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPR unscaled\n",
    "\n",
    "collection_SPR = main(\n",
    "    identifier='kernel_matrix',\n",
    "    data=data_malaria,\n",
    "    kernel_param=kernel_comb_sig_poly_rbf,\n",
    "    kernel_for_time_series=\"sigmoid_kernel\",\n",
    "    kernel_for_dosage=\"poly_kernel\",\n",
    "    kernel_for_abSignal=\"rbf_kernel\",\n",
    "    save_to_dir=os.path.join(kerneldir, 'unscaled'),\n",
    ")\n",
    "fn = os.path.join(kerneldir, 'unfiltered/collected_damping_info_SPR.json')\n",
    "with open(fn, 'w') as fp:\n",
    "    json.dump({x: collection_SPR[x] for x in collection_SPR if x not in 'kernel_matrices'}, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overview(collection_SPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RPR unscaled\n",
    "\n",
    "collection_RPR = main(\n",
    "    identifier='kernel_matrix',\n",
    "    data=data_malaria,\n",
    "    kernel_param=kernel_comb_rbf_poly_rbf,\n",
    "    kernel_for_time_series=\"rbf_kernel\",\n",
    "    kernel_for_dosage=\"poly_kernel\",\n",
    "    kernel_for_abSignal=\"rbf_kernel\",\n",
    "    save_to_dir=os.path.join(kerneldir, 'unscaled'),\n",
    ")\n",
    "fn = os.path.join(kerneldir, 'unfiltered/collected_damping_info_RPR.json')\n",
    "with open(fn, 'w') as fp:\n",
    "    json.dump({x: collection_RPR[x] for x in collection_RPR if x not in 'kernel_matrices'}, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overview(collection_RPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPP unscaled\n",
    "\n",
    "collection_SPP = main(\n",
    "    identifier='kernel_matrix',\n",
    "    data=data_malaria,\n",
    "    kernel_param=kernel_comb_sig_poly_poly,\n",
    "    kernel_for_time_series=\"sigmoid_kernel\",\n",
    "    kernel_for_dosage=\"poly_kernel\",\n",
    "    kernel_for_abSignal=\"poly_kernel\",\n",
    "    save_to_dir=os.path.join(kerneldir, 'unscaled'),\n",
    ")\n",
    "fn = os.path.join(kerneldir, 'unfiltered/collected_damping_info_SPP.json')\n",
    "with open(fn, 'w') as fp:\n",
    "    json.dump({x: collection_SPP[x] for x in collection_SPP if x not in 'kernel_matrices'}, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overview(collection_SPP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RPP unscaled\n",
    "\n",
    "collection_RPP = main(\n",
    "    identifier='kernel_matrix',\n",
    "    data=data_malaria,\n",
    "    kernel_param=kernel_comb_rbf_poly_poly,\n",
    "    kernel_for_time_series=\"rbf_kernel\",\n",
    "    kernel_for_dosage=\"poly_kernel\",\n",
    "    kernel_for_abSignal=\"poly_kernel\",\n",
    "    save_to_dir=os.path.join(kerneldir, 'unscaled'),\n",
    ")\n",
    "fn = os.path.join(kerneldir, 'unfiltered/collected_damping_info_RPP.json')\n",
    "with open(fn, 'w') as fp:\n",
    "    json.dump({x: collection_RPP[x] for x in collection_RPP if x not in 'kernel_matrices'}, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overview(collection_RPP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_label_vec = data_malaria_sorted.loc[:, \"Patient\":\"TimePointOrder\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_label_vec.to_csv(os.path.join(kerneldir, \"unfiltered/target_label_vec.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SelectiveSet SRR unscaled\n",
    "\n",
    "collection_SRR = main(\n",
    "    identifier='kernel_matrix_SelectiveSet',\n",
    "    data=selected_data_malaria,\n",
    "    kernel_param=kernel_comb_sig_rbf_rbf,\n",
    "    kernel_for_time_series=\"sigmoid_kernel\",\n",
    "    kernel_for_dosage=\"rbf_kernel\",\n",
    "    kernel_for_abSignal=\"rbf_kernel\",\n",
    "    save_to_dir=os.path.join(kerneldir, 'unscaled'),\n",
    ")\n",
    "fn = os.path.join(kerneldir, 'unfiltered/collected_damping_info_SelectiveSet_SRR.json')\n",
    "with open(fn, 'w') as fp:\n",
    "    json.dump({x: collection_SRR[x] for x in collection_SRR if x not in 'kernel_matrices'}, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overview(collection_SRR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SelectiveSet RRR unscaled\n",
    "\n",
    "collection_RRR = main(\n",
    "    identifier='kernel_matrix_SelectiveSet',\n",
    "    data=selected_data_malaria,\n",
    "    kernel_param=kernel_comb_rbf_rbf_rbf,\n",
    "    kernel_for_time_series=\"rbf_kernel\",\n",
    "    kernel_for_dosage=\"rbf_kernel\",\n",
    "    kernel_for_abSignal=\"rbf_kernel\",\n",
    "    save_to_dir=os.path.join(kerneldir, 'unscaled'),\n",
    ")\n",
    "fn = os.path.join(kerneldir, 'unfiltered/collected_damping_info_SelectiveSet_RRR.json')\n",
    "with open(fn, 'w') as fp:\n",
    "    json.dump({x: collection_RRR[x] for x in collection_RRR if x not in 'kernel_matrices'}, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overview(collection_RRR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SelectiveSet SRP unscaled\n",
    "\n",
    "collection_SRP = main(\n",
    "    identifier='kernel_matrix_SelectiveSet',\n",
    "    data=selected_data_malaria,\n",
    "    kernel_param=kernel_comb_sig_rbf_poly,\n",
    "    kernel_for_time_series=\"sigmoid_kernel\",\n",
    "    kernel_for_dosage=\"rbf_kernel\",\n",
    "    kernel_for_abSignal=\"poly_kernel\",\n",
    "    save_to_dir=os.path.join(kerneldir, 'unscaled'),\n",
    ")\n",
    "fn = os.path.join(kerneldir, 'unfiltered/collected_damping_info_SelectiveSet_SRP.json')\n",
    "with open(fn, 'w') as fp:\n",
    "    json.dump({x: collection_SRP[x] for x in collection_SRP if x not in 'kernel_matrices'}, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overview(collection_SRP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SelectiveSet RRP unscaled\n",
    "\n",
    "collection_RRP = main(\n",
    "    identifier='kernel_matrix_SelectiveSet',\n",
    "    data=selected_data_malaria,\n",
    "    kernel_param=kernel_comb_rbf_rbf_poly,\n",
    "    kernel_for_time_series=\"rbf_kernel\",\n",
    "    kernel_for_dosage=\"rbf_kernel\",\n",
    "    kernel_for_abSignal=\"poly_kernel\",\n",
    "    save_to_dir=os.path.join(kerneldir, 'unscaled'),\n",
    ")\n",
    "fn = os.path.join(kerneldir, 'unfiltered/collected_damping_info_SelectiveSet_RRP.json')\n",
    "with open(fn, 'w') as fp:\n",
    "    json.dump({x: collection_RRP[x] for x in collection_RRP if x not in 'kernel_matrices'}, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overview(collection_RRP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SelectiveSet SPR unscaled\n",
    "\n",
    "collection_SPR = main(\n",
    "    identifier='kernel_matrix_SelectiveSet',\n",
    "    data=selected_data_malaria,\n",
    "    kernel_param=kernel_comb_sig_poly_rbf,\n",
    "    kernel_for_time_series=\"sigmoid_kernel\",\n",
    "    kernel_for_dosage=\"poly_kernel\",\n",
    "    kernel_for_abSignal=\"rbf_kernel\",\n",
    "    save_to_dir=os.path.join(kerneldir, 'unscaled'),\n",
    ")\n",
    "fn = os.path.join(kerneldir, 'unfiltered/collected_damping_info_SelectiveSet_SPR.json')\n",
    "with open(fn, 'w') as fp:\n",
    "    json.dump({x: collection_SPR[x] for x in collection_SPR if x not in 'kernel_matrices'}, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overview(collection_SPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SelectiveSet RPR unscaled\n",
    "\n",
    "collection_RPR = main(\n",
    "    identifier='kernel_matrix_SelectiveSet',\n",
    "    data=selected_data_malaria,\n",
    "    kernel_param=kernel_comb_rbf_poly_rbf,\n",
    "    kernel_for_time_series=\"rbf_kernel\",\n",
    "    kernel_for_dosage=\"poly_kernel\",\n",
    "    kernel_for_abSignal=\"rbf_kernel\",\n",
    "    save_to_dir=os.path.join(kerneldir, 'unscaled'),\n",
    ")\n",
    "fn = os.path.join(kerneldir, 'unfiltered/collected_damping_info_SelectiveSet_RPR.json')\n",
    "with open(fn, 'w') as fp:\n",
    "    json.dump({x: collection_RPR[x] for x in collection_RPR if x not in 'kernel_matrices'}, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overview(collection_RPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SelectiveSet SPP unscaled\n",
    "\n",
    "collection_SPP = main(\n",
    "    identifier='kernel_matrix_SelectiveSet',\n",
    "    data=selected_data_malaria,\n",
    "    kernel_param=kernel_comb_sig_poly_poly,\n",
    "    kernel_for_time_series=\"sigmoid_kernel\",\n",
    "    kernel_for_dosage=\"poly_kernel\",\n",
    "    kernel_for_abSignal=\"poly_kernel\",\n",
    "    save_to_dir=os.path.join(kerneldir, 'unscaled'),\n",
    ")\n",
    "fn = os.path.join(kerneldir, 'unfiltered/collected_damping_info_SelectiveSet_SPP.json')\n",
    "with open(fn, 'w') as fp:\n",
    "    json.dump({x: collection_SPP[x] for x in collection_SPP if x not in 'kernel_matrices'}, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overview(collection_SPP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SelectiveSet RPP unscaled\n",
    "\n",
    "collection_RPP = main(\n",
    "    identifier='kernel_matrix_SelectiveSet',\n",
    "    data=selected_data_malaria,\n",
    "    kernel_param=kernel_comb_rbf_poly_poly,\n",
    "    kernel_for_time_series=\"rbf_kernel\",\n",
    "    kernel_for_dosage=\"poly_kernel\",\n",
    "    kernel_for_abSignal=\"poly_kernel\",\n",
    "    save_to_dir=os.path.join(kerneldir, 'unscaled'),\n",
    ")\n",
    "fn = os.path.join(kerneldir, 'unfiltered/collected_damping_info_SelectiveSet_RPP.json')\n",
    "with open(fn, 'w') as fp:\n",
    "    json.dump({x: collection_RPP[x] for x in collection_RPP if x not in 'kernel_matrices'}, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overview(collection_RPP)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 ('malaria_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "83a893cf0f1a8abdb34bbe7579767ee7f797eeb51a1ad0278dbd56f81fb375ef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
